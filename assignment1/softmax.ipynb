{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28f3f7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from Tools.data_utils import load_CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e49a56c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape:  (50000, 3072)\n",
      "Training labels shape:  (50000,)\n",
      "Test data shape:  (10000, 3072)\n",
      "Test labels shape:  (10000,)\n"
     ]
    }
   ],
   "source": [
    "cifar10_dir = 'C:/Users/rainstar/Jupyter Folder/cs231n/cifar-10-batches-py/'\n",
    "\n",
    "try:\n",
    "    del X_train,Y_train\n",
    "    del X_test,Y_test\n",
    "    print('Clear previously loaded data')\n",
    "except:\n",
    "    pass\n",
    "\n",
    "X_train,Y_train,X_test,Y_test = load_CIFAR10(cifar10_dir)\n",
    "\n",
    "print('Training data shape: ',X_train.shape)\n",
    "print('Training labels shape: ',Y_train.shape)\n",
    "print('Test data shape: ',X_test.shape)\n",
    "print('Test labels shape: ',Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8384128",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape:  (49000, 3072)\n",
      "Train labels shape:  (49000,)\n",
      "Validation data shape:  (1000, 3072)\n",
      "Validation labels shape:  (1000,)\n",
      "Test data shape:  (1000,)\n",
      "Test labels shape:  (1000,)\n"
     ]
    }
   ],
   "source": [
    "num_train = 49000\n",
    "num_validation = 1000\n",
    "num_test = 1000\n",
    "num_dev =  500\n",
    "\n",
    "mask = range(num_train,num_train+num_validation)\n",
    "X_val = X_train[mask]\n",
    "Y_val = Y_train[mask].astype('int')\n",
    "\n",
    "mask = range(num_train)\n",
    "X_train = X_train[mask]\n",
    "Y_train = Y_train[mask].astype('int')\n",
    "\n",
    "mask = range(num_test)\n",
    "X_test = X_test[mask]\n",
    "Y_test = Y_test[mask].astype('int')\n",
    "\n",
    "mask = np.random.choice(num_train,num_dev,replace=True)\n",
    "X_dev = X_train[mask]\n",
    "Y_dev = Y_train[mask].astype('int')\n",
    "\n",
    "print('Train data shape: ', X_train.shape)\n",
    "print('Train labels shape: ', Y_train.shape)\n",
    "print('Validation data shape: ', X_val.shape)\n",
    "print('Validation labels shape: ', Y_val.shape)\n",
    "print('Test data shape: ', Y_test.shape)\n",
    "print('Test labels shape: ', Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41c10522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:  (49000, 3073)\n",
      "X_val:  (1000, 3073)\n",
      "X_test:  (1000, 3073)\n",
      "X_dev:  (500, 3073)\n"
     ]
    }
   ],
   "source": [
    "# normalize\n",
    "mean_image = np.mean(X_train,axis=0)\n",
    "\n",
    "X_train -= mean_image\n",
    "X_val -= mean_image\n",
    "X_test -= mean_image\n",
    "X_dev -= mean_image\n",
    "\n",
    "# append bias\n",
    "X_train = np.hstack([X_train,np.ones((X_train.shape[0],1))])\n",
    "X_val = np.hstack([X_val,np.ones((X_val.shape[0],1))])\n",
    "X_test = np.hstack([X_test,np.ones((X_test.shape[0],1))])\n",
    "X_dev = np.hstack([X_dev,np.ones((X_dev.shape[0],1))])\n",
    "\n",
    "print('X_train: ',X_train.shape)\n",
    "print('X_val: ',X_val.shape)\n",
    "print('X_test: ',X_test.shape)\n",
    "print('X_dev: ',X_dev.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "949ceab0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  2.3901293995394086\n",
      "loss:  2.3901293995394086\n"
     ]
    }
   ],
   "source": [
    "from Tools.classifiers.softmax import *\n",
    "\n",
    "W = np.random.randn(3073,10) * 0.0001\n",
    "\n",
    "loss1,grad1 = softmax_loss_naive(W,X_dev,Y_dev,0.0)\n",
    "print('loss: ',loss1)\n",
    "\n",
    "loss2,grad2 = softmax_loss_vectorized(W,X_dev,Y_dev,0.0)\n",
    "print('loss: ',loss2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "802026fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr 5e-08 regu 25000.0 : train_acc0.31587755102040815 val_acc0.324\n",
      "lr 5e-08 regu 50000.0 : train_acc0.3187755102040816 val_acc0.329\n",
      "lr 1e-07 regu 25000.0 : train_acc0.3451836734693878 val_acc0.361\n",
      "lr 1e-07 regu 50000.0 : train_acc0.32026530612244897 val_acc0.336\n",
      "lr 5e-07 regu 25000.0 : train_acc0.340265306122449 val_acc0.358\n",
      "lr 5e-07 regu 50000.0 : train_acc0.3146734693877551 val_acc0.329\n"
     ]
    }
   ],
   "source": [
    "from Tools.classifiers.linear_classifier import *\n",
    "\n",
    "best_val = -1\n",
    "best_softmax = None\n",
    "\n",
    "learning_rates = [5e-8,1e-7,5e-7]\n",
    "regularizations = [2.5e4,5e4]\n",
    "\n",
    "for lr in learning_rates:\n",
    "    for reg in regularizations:\n",
    "        softmax = LinearSoftmax()\n",
    "        softmax.train(X_train,Y_train,learning_rate=lr,\n",
    "                     regu=reg,num_iters=1500,batch_size=200,\n",
    "                     verbose=False)\n",
    "        train_acc = np.mean(Y_train==softmax.predict(X_train))\n",
    "        val_acc = np.mean(Y_val==softmax.predict(X_val))\n",
    "        print(\"lr {} regu {} : train_acc{} val_acc{}\".format(lr,reg,\n",
    "                                                            train_acc,\n",
    "                                                            val_acc))\n",
    "        if val_acc>best_val:\n",
    "            best_val = val_acc\n",
    "            best_softmax = softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "302a4eff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "softmax final accuracy on test set:  0.355\n"
     ]
    }
   ],
   "source": [
    "Y_test_pred = best_softmax.predict(X_test)\n",
    "test_acc = np.mean(Y_test == Y_test_pred)\n",
    "print(\"softmax final accuracy on test set: \",test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c74a9eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
